{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Note:run in python2######\n",
    "#ARCHITECTURE \n",
    "# ONE CNN LAYER WITH KERNEL SIZE(5,5) AND 32 SUCH KERNELS\n",
    "# ONE UNRAVELING MATRIX\n",
    "# ONE FULLY CONNECTED LAYER TO OUTPUT USING SOFTMAX\n",
    "# TRAIN DATA ONLY 100 SAMPLES USED AND TESTED AGAINST ONLY 30 SAMPLES\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "np.random.seed(69)\n",
    "########################################################################\n",
    "#initialise all parameters fo CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVOLUTION NEURAL NETWORK CONVOLUTION FUNCTION\n",
    "\n",
    "#FORWARD NETWORK\n",
    "def outdim(N,M,s,pad):\n",
    "    if pad =='valid':\n",
    "        return (N-M)/s+1\n",
    "    return N\n",
    "\n",
    "def init(img,L,M,filt_num1,filt_num2):\n",
    "\n",
    "    kernelMatrix=[np.random.normal(1e-4,1,(filt_num1,5, 5 ,img.shape[-1])),np.random.normal(1e-4,1,(filt_num2,5,5,filt_num1))] \n",
    "    biasMatrix  =[]\n",
    "    biasMatrix.append(np.random.normal(0,0.1,(kernelMatrix[0].shape[0])))\n",
    "    biasMatrix.append(np.random.normal(0,0.1,(kernelMatrix[1].shape[0])))\n",
    "    WMatrix=1.0/M*np.random.normal(0,1,(L,M))\n",
    "\n",
    "    return kernelMatrix,biasMatrix,WMatrix\n",
    "\n",
    "\n",
    "\n",
    "def exceptions(img,conv_filter):\n",
    "\n",
    "    if len(img.shape) > 2 or len(conv_filter.shape) > 3: # Check if number of image channels matches the filter depth.\n",
    "        if img.shape[-1] != conv_filter.shape[-1]:\n",
    "            print(\"Error: Number of channels in both image and filter must match.\")\n",
    "            sys.exit()\n",
    "\n",
    "#a function to pad the input with zeros along column and rows\n",
    "\n",
    "def pad_input(img, Mrow, Mcol, stride):\n",
    "\n",
    "    N = img.shape[0]\n",
    "\n",
    "    ##padding along rows\n",
    "    p1 = int(math.ceil(((img.shape[0]-1)*(stride[0]) + Mrow -img.shape[0])/2))\n",
    "    for i in range(0,p1):\n",
    "        img=np.vstack((np.zeros((1,img.shape[1],img.shape[2])),img))\n",
    "        img=np.vstack((img,np.zeros((1,img.shape[1],img.shape[2]))))\n",
    "\n",
    "    #padding along column\n",
    "    p2 = int(math.ceil(((img.shape[1]-1)*(stride[1]) + Mcol -img.shape[1])/2))\n",
    "    for i in range(0,p2):\n",
    "        img=np.hstack((np.zeros((img.shape[0],1,img.shape[2])),img))\n",
    "        img=np.hstack((img,np.zeros((img.shape[0],1,img.shape[2]))))\n",
    "\n",
    "    return img\n",
    "\n",
    "def apply_activationCONV(Activation_function,inp):\n",
    "    \n",
    "    #activation functions\n",
    "    if Activation_function == \"relu\":\n",
    "        return np.where(inp<0,0,inp)\n",
    "    elif Activation_function == \"tanh\":\n",
    "        return np.tanh(inp)\n",
    "    elif Activation_function == \"sigmoid\":\n",
    "        return 1.0/(1+np.exp(-1.0*inp))\n",
    "    else:\n",
    "        return inp\n",
    "\n",
    "\n",
    "def conv(img, conv_filter, padding, stride, Activation_function, bias):\n",
    "\n",
    "    # print img.shape\n",
    "    if padding == 'same':\n",
    "\n",
    "        img = np.array(pad_input(img,conv_filter.shape[1],conv_filter.shape[2],stride))\n",
    "        # print img.shape\n",
    "\n",
    "    # see for exceptions\n",
    "    \n",
    "    exceptions(img,conv_filter)\n",
    "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
    "    preconv = np.zeros((   (img.shape[0]-conv_filter.shape[1])/stride[0] + 1 , \n",
    "                                (img.shape[1]-conv_filter.shape[2])/stride[1] + 1 , conv_filter.shape[0] ))\n",
    "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
    "    feature_maps = np.zeros((   (img.shape[0]-conv_filter.shape[1])/stride[0] + 1 , \n",
    "                                (img.shape[1]-conv_filter.shape[2])/stride[1] + 1 , conv_filter.shape[0] ))\n",
    "    # Convolving the image by the filter(s).\n",
    "    for filter_num in range(conv_filter.shape[0]):\n",
    "\n",
    "        curr_filter = conv_filter[filter_num, :]\n",
    "\n",
    "        filter_sizeRow = curr_filter.shape[0]\n",
    "\n",
    "        filter_sizeCol = curr_filter.shape[1]\n",
    "\n",
    "        #Applying the convolution operation.\n",
    "        r2=0\n",
    "        for r in np.arange(0,img.shape[0]-filter_sizeRow+1,stride[0]):\n",
    "            c2=0\n",
    "            for c in np.arange(0,img.shape[1]-filter_sizeCol+1,stride[1]):\n",
    "                #Region required\n",
    "                curr_region = img[r:r+filter_sizeRow,c:c+filter_sizeCol,:]\n",
    "                #Element-wise multipliplication between the current region and the filter.\n",
    "                curr_result = curr_region * curr_filter\n",
    "                #Summing the result of multiplication.\n",
    "                feature_maps[r2,c2, filter_num] =np.sum(curr_result)\n",
    "                c2=c2+1\n",
    "            r2=r2+1\n",
    "        preconv[:,:,filter_num]=feature_maps[:,:,filter_num]+bias[filter_num]\n",
    "        feature_maps[:,:,filter_num]=apply_activationCONV(Activation_function,preconv[:,:,filter_num])\n",
    "    \n",
    "    return feature_maps,preconv # Returning all feature maps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is the pooling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling functions\n",
    "#ker_shape=(2,2)\n",
    "def pool(img,ker_shape,stride):\n",
    "    ker_rows = ker_shape[0]\n",
    "    ker_cols = ker_shape[1]\n",
    "    i=0\n",
    "    j=0\n",
    "    k=0\n",
    "    l=0\n",
    "    mask = np.zeros(img.shape)\n",
    "    new_shape = (int((img.shape[0]-ker_rows)/stride[0])+1,int((img.shape[1]-ker_cols)/stride[1])+1)\n",
    "    out = np.zeros(new_shape)\n",
    "    while(1):\n",
    "        if ker_rows+i > img.shape[0]:\n",
    "            break\n",
    "        else:\n",
    "            while(1):\n",
    "                if ker_cols+j > img.shape[1]: ### we reached the end of set corresponding to the current row\n",
    "                    j=0\n",
    "                    l=0\n",
    "                    i=i+stride[0]\n",
    "                    k=k+1\n",
    "                    break\n",
    "                else:\n",
    "                    temp = img[i:ker_rows+i,j:ker_cols+j]\n",
    "                    temp1 = temp.reshape(-1,1)\n",
    "                    temp2 = mask[i:ker_rows+i,j:ker_cols+j]\n",
    "                    temp2 = temp2.reshape(-1,1)\n",
    "                    temp2[np.argmax(temp1)] = 1\n",
    "                    mask[i:ker_rows+i,j:ker_cols+j] = temp2.reshape((ker_rows,ker_cols))\n",
    "                    out[k][l] = np.max(temp)\n",
    "                    j=j+stride[1]\n",
    "                    l=l+1\n",
    "    return (out,mask)\n",
    "\n",
    "def pool_volume(img,ker_shape,stride):\n",
    "    depth = img.shape[2]\n",
    "    temp1 = []\n",
    "    masks = []\n",
    "    i=0\n",
    "    while(i<depth):\n",
    "        temp,mask = pool(img[:,:,i],ker_shape,stride)\n",
    "        temp1.append(temp)\n",
    "        masks.append(mask)\n",
    "        i=i+1\n",
    "    temp1 = np.array(temp1)\n",
    "    masks = np.array(masks)\n",
    "    shape = temp1.shape\n",
    "    shape1 = masks.shape\n",
    "    temp1 = temp1.reshape(shape[0],shape[1],shape[2])\n",
    "    masks = masks.reshape(shape1[0],shape1[1],shape1[2])\n",
    "    output_volume = np.zeros((shape[1],shape[2],shape[0]))\n",
    "    masks_volume = np.zeros((shape1[1],shape1[2],shape1[0]))\n",
    "    for i in range(depth):\n",
    "        output_volume[:,:,i] = temp1[i,:,:]\n",
    "        masks_volume[:,:,i] = masks[i,:,:] \n",
    "    return (output_volume,masks_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "\n",
    "#unraveling function\n",
    "def unraveling(inp,WMatrix):\n",
    "\n",
    "    flatten = np.array(inp.flatten()).reshape(-1,1)\n",
    "\n",
    "    return np.array(np.matmul(WMatrix,flatten))\n",
    "\n",
    "\n",
    "\n",
    "##########\n",
    "#display the output of the layers\n",
    "\n",
    "def display(feature_maps,poolOut,NoOfConv,kernelMatrix):\n",
    "    \n",
    "    print('Displaying output per channel of a given volume')\n",
    "\n",
    "    for i in range(0,NoOfConv):\n",
    "        print('LAYER: '+str(i+1))\n",
    "        print('Kenels per layer shape'+str((kernelMatrix[i]).shape))\n",
    "        print('Convolution output'+str((feature_maps[i]).shape))\n",
    "        print('Pooling output'+str((poolOut[i]).shape))\n",
    "        for j in range(0,feature_maps[i].shape[2]):\n",
    "            plt.title('Layer:'+str(i+1)+' Activation_maps[:,:,'+str(j)+']')\n",
    "            plt.imshow((feature_maps[i])[:,:,j],cmap=\"gray\")\n",
    "            plt.show()\n",
    "            plt.title('After pooling PoolOut[:,:,'+str(j)+']')\n",
    "            plt.imshow((poolOut[i])[:,:,j],cmap=\"gray\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp forward pass\n",
    "#layer\n",
    "def layer(w,x,b):\n",
    "    out = np.matmul(w,x)+b\n",
    "    return out\n",
    "\n",
    "def apply_activationMLP(Activation_function,inp):\n",
    "    \n",
    "    #activation functions\n",
    "    if Activation_function == \"relu\":\n",
    "        return np.where(inp<0,0,inp)\n",
    "    elif Activation_function == \"tanh\":\n",
    "        return np.tanh(inp)\n",
    "    elif Activation_function == \"sigmoid\":\n",
    "        return 1.0/(1+np.exp(-1.0*inp))\n",
    "    elif Activation_function == \"softmax\":\n",
    "        return (1.0/(np.sum(np.exp(inp),axis=0)))*(np.exp(inp))\n",
    "\n",
    "#forward path\n",
    "def forward_path(X,W,b,Activation_function='softmax'):\n",
    "\n",
    "   \n",
    "    z=apply_activationMLP(Activation_function,np.array(layer(W,X,b)))\n",
    "\n",
    "    out = (np.array(z))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#Backpropagation\n",
    "#convolution backprop\n",
    "#derivative of relu\n",
    "\n",
    "def conv_backprop(arr,ker):\n",
    "    ker_rows = ker.shape[0]\n",
    "    ker_cols = ker.shape[1]\n",
    "    ker = ker.reshape(ker_rows,ker_cols,1)\n",
    "    i=0\n",
    "    j=0\n",
    "    k=0\n",
    "    l=0\n",
    "    new_shape = (int((arr.shape[0]-ker_rows))+1,int((arr.shape[1]-ker_cols))+1,arr.shape[2])\n",
    "    out = np.zeros(new_shape)\n",
    "    while(1):\n",
    "        if ker_rows+i > arr.shape[0]:\n",
    "            break\n",
    "        else:\n",
    "            while(1):\n",
    "                if ker_cols+j > arr.shape[1]: ### we reached the end of set corresponding to the current row\n",
    "                    j=0\n",
    "                    l=0\n",
    "                    i=i+1\n",
    "                    k=k+1\n",
    "                    break\n",
    "                else:\n",
    "                    temp = arr[i:ker_rows+i,j:ker_cols+j,:]\n",
    "                    tmp = np.sum(temp*ker,axis=1)\n",
    "                    out[k][l] = np.sum(tmp,axis=0)\n",
    "                    j=j+1\n",
    "                    l=l+1\n",
    "    return out\n",
    "\n",
    "def conv_backprop_volume(arr,kernel):\n",
    "    depth  = kernel.shape[2]\n",
    "    temp1  = []\n",
    "    i=0\n",
    "    while(i<depth):\n",
    "        temp = conv_backprop(arr,kernel[:,:,i])\n",
    "        temp1.append(temp)\n",
    "        i=i+1\n",
    "    temp1 = np.array(temp1)\n",
    "    return temp1\n",
    "\n",
    "\n",
    "def der_relu(inp):\n",
    "    return np.where(inp<0,0,1)\n",
    "\n",
    "def ConvBackprop(dy,z,W,M,x,pool1,preconv2,pool2,mask_inp2,filt2):\n",
    "    #MLP LAYER\n",
    "    dW=np.matmul(dy,z.T)\n",
    "    db=dy.reshape(len(dy),1)\n",
    "    #Unraveling layer\n",
    "    #let us call M as the unraveling matrix\n",
    "    s=np.matmul(W.T,dy)\n",
    "\n",
    "    dM=np.matmul(s,x.T)\n",
    "    #Convolutional layer\n",
    "    #gradient with respect to flattened array of pool2 \n",
    "    gradf = np.matmul(M.T,s)\n",
    "\n",
    "    #found the gradient wrt the flattened vector reshaping it to pooling layer size\n",
    "\n",
    "    gradPool2 = gradf.reshape((pool2.shape[0],pool2.shape[1],pool2.shape[2]))  \n",
    "\n",
    "    ####\n",
    "    #comvolutional layer backprop\n",
    "    #following the architecture in sildes and taking the pooling function as average pooling\n",
    "    gradConv2 = np.repeat(gradPool2 ,2,axis=0)\n",
    "    gradConv2 = np.repeat(gradConv2,2,axis=1)\n",
    "    #multiplication with derivative of relu\n",
    "    gradConv2 = mask_inp2*gradConv2*der_relu(preconv2)\n",
    "    #since padding is 'same' according to architecture\n",
    "\n",
    "    #pool1Rot=np.rot90(pad_input(pool1,filt2.shape[1],filt2.shape[2],(1,1)),2,(0,1))\n",
    "    pool1Rot=pad_input(pool1,filt2.shape[1],filt2.shape[2],(1,1))\n",
    "    bias=np.zeros(filt2.shape[0]) \n",
    "\n",
    "    #function parameters\n",
    "    #conv(img, conv_filter, padding, stride, Activation_function, bias)\n",
    "    \n",
    "    dfilt2 = conv_backprop_volume(pool1Rot,gradConv2)\n",
    "    \n",
    "    dbias2=np.sum(gradConv2,axis=(0,1)).reshape(-1,1)\n",
    "    \n",
    "    return dW,db,dM,dfilt2,dbias2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('trainDataX shape:', (60000, 28, 28, 1))\n",
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n",
      "((60000,), 'train labels')\n",
      "(10000, 'train labels')\n"
     ]
    }
   ],
   "source": [
    "#only to import data\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "np.random.seed(69)\n",
    "################################\n",
    "# Training parameters\n",
    "batch_size = 50\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "learningRate=0.001\n",
    "\n",
    "################################\n",
    "\n",
    "#import data\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(trainDataX, trainLabelY_num), (testDataX, testLabelY_num) = mnist.load_data()\n",
    "\n",
    "trainDataX = trainDataX.reshape(trainDataX.shape[0], img_rows, img_cols, 1)\n",
    "testDataX = testDataX.reshape(testDataX.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "trainDataX = trainDataX.astype('float32')\n",
    "\n",
    "testDataX = testDataX.astype('float32')\n",
    "trainDataX /= 255.0\n",
    "testDataX /= 255.0\n",
    "print('trainDataX shape:', trainDataX.shape)\n",
    "print(trainDataX.shape[0], 'train samples')\n",
    "print(testDataX.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "trainLabelY = keras.utils.to_categorical(trainLabelY_num, num_classes)\n",
    "print(trainLabelY_num.shape, 'train labels')\n",
    "testLabelY = keras.utils.to_categorical(testLabelY_num, num_classes)\n",
    "print(testLabelY.shape[0], 'train labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in range(10):\n",
    "    t = np.argwhere(trainLabelY_num == i)\n",
    "    x_train.append(trainDataX[t[0:10]])\n",
    "    y_train.append(trainLabelY[t[0:10]])\n",
    "    x_test.append(testDataX[t[20:23]])\n",
    "    y_test.append(testLabelY[t[20:23]])\n",
    "    \n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train = x_train.reshape(100,28,28,1)\n",
    "y_train = y_train.reshape(100,10)\n",
    "y_test = y_test.reshape(30,10)\n",
    "x_test = x_test.reshape(30,28,28,1)\n",
    "print x_train[50,:,:,:].shape\n",
    "plt.imshow(x_train[50,:,:,0],cmap=\"gray\")\n",
    "plt.show()\n",
    "print(y_train[50,:])\n",
    "import cv2 \n",
    "plt.imsave('5.jpg',x_train[50,:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialisation of initial weights\n",
    "### initialisations\n",
    "kernel1 = np.random.normal(0,1,(32,5,5,1))\n",
    "bias1   = np.random.normal(0,1,(32,1))\n",
    "WMatrix = np.random.uniform(0,1e-3,(1024,14*14*32))\n",
    "W = np.random.uniform(0,1e-3,(10,1024))\n",
    "b = np.random.uniform(0,1e-3,(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training of neural network starts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 50\n",
      "Epoch:    0\n",
      "Loss:[3096.14710399]\n",
      "Epoch:    1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saiashish/.local/lib/python2.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in exp\n",
      "/home/saiashish/.local/lib/python2.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "print('Batch size: '+str(batch_size))\n",
    "for i in range(epochs):\n",
    "### forward pass\n",
    "    print('Epoch:    '+str(i))\n",
    "    loss=0\n",
    "    for j in np.arange(0,x_train.shape[0],batch_size):\n",
    "\n",
    "        dW = np.zeros(W.shape)\n",
    "        db = np.zeros(b.shape)\n",
    "        dWMatrix = np.zeros(WMatrix.shape)\n",
    "        dkernel1  = np.zeros(kernel1.shape)\n",
    "        dbias1  = np.zeros(bias1.shape)\n",
    "        for k in range(0,batch_size):\n",
    "            bias1=bias1.reshape((-1,1))\n",
    "            conv_out1,preconv1 = conv(x_train[j+k,:,:,:],kernel1,'same',(5,5),'relu',bias1)\n",
    "            pool_out1,mask_inp1 = pool_volume(conv_out1,(2,2),(2,2))\n",
    "            # conv_out2 = conv_volume(padd_inp2,W_conv2,(1,1),\"relu\")\n",
    "            # pool_out2,mask_inp2 = pool_volume(conv_out2,(2,2),(2,2))\n",
    "\n",
    "            x = pool_out1.reshape(-1,1)\n",
    "            z = unraveling(x,WMatrix).reshape(-1,1)\n",
    "            y = forward_path(z,W,b,\"softmax\").reshape(-1,1)\n",
    "            loss = loss -np.log(y[np.argmax(y_train[j+k:,])])\n",
    "\n",
    "            ### backprop starts here\n",
    "            dy = (y-y_train[j+k,:].reshape(-1,1)).reshape(-1,1)\n",
    "\n",
    "            #taking activation funtion as softmax\n",
    "            #ConvBackprop(dy,z,W,x,pool1,preconv2,pool2,mask_inp2,filt2):\n",
    "            a,b,c,d,e=ConvBackprop(dy,z,W,WMatrix,x,x_train[j+k,:,:,:]\n",
    "                                                  ,preconv1,pool_out1,mask_inp1,kernel1)\n",
    "            \n",
    "            dW=dW+a\n",
    "            db=db+b\n",
    "            dWMatrix=dWMatrix+c\n",
    "            dkernel1=dkernel1+d\n",
    "            dbias1=dbias1+e\n",
    "\n",
    "    \n",
    "        kernel1 = kernel1 - learningRate*dkernel1\n",
    "        bias1   = bias1 - learningRate*dbias1\n",
    "        W   = W - learningRate*dW\n",
    "        b   = b - learningRate*db\n",
    "        WMatrix = WMatrix - learningRate*dWMatrix\n",
    "    print('Loss:'+str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the training loss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x=np.array([726.67833344,444.88589961,408.66810016,320.19270798,319.02296175,318.4638766,318.03905017,317.62947854,317.19363297,316.71020752,316.16381979,315.54112162,314.82984713,314.01876391,313.09802404,312.05984855,310.89947914,309.61622971,308.21439066,306.70384559,305.10007863,303.42354671,301.69830033,299.94980987,298.20294795,296.4802233,294.80122223,293.18756827,291.6936808,290.66723773])\n",
    "plt.plot(x)\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()\n",
    "#without shuffle it tries to overfit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing loss has been calculated with the same architecture with shuffle CNN_1layer_Shuffle.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(y):\n",
    "    return np.argmax(y)\n",
    "\n",
    "yvect=[]\n",
    "y_trurevect=[]\n",
    "\n",
    "for i in range(0,x_train.shape[0]):\n",
    "    conv_out1,preconv1 = conv(x_train[i,:,:,:],kernel1,'same',(5,5),'relu',bias1)\n",
    "    pool_out1,mask_inp1 = pool_volume(conv_out1,(2,2),(2,2))\n",
    "    x = pool_out1.reshape(-1,1)\n",
    "    z = unraveling(x,WMatrix).reshape(-1,1)\n",
    "    y = forward_path(z,W,b,\"softmax\").reshape(-1,1)\n",
    "    yvect.append(predict(y))\n",
    "    y_trurevect.append(predict(y_train[i,:]))\n",
    "#predicting train accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_trurevect, yvect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yvect=[]\n",
    "y_trurevect=[]\n",
    "\n",
    "for i in range(0,x_test.shape[0]):\n",
    "    conv_out1,preconv1 = conv(x_test[i,:,:,:],kernel1,'same',(5,5),'relu',bias1)\n",
    "    pool_out1,mask_inp1 = pool_volume(conv_out1,(2,2),(2,2))\n",
    "    x = pool_out1.reshape(-1,1)\n",
    "    z = unraveling(x,WMatrix).reshape(-1,1)\n",
    "    y = forward_path(z,W,b,\"softmax\").reshape(-1,1)\n",
    "    yvect.append(predict(y))\n",
    "    y_trurevect.append(predict(y_test[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting test accuracy\n",
    "print(accuracy_score(y_trurevect, yvect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POINT TO UNDERSTAND THE ACCURACY IS LOW DUE TO SMALL ARCHITECTURE IE ONLY ONE CNN LAYER AND LESS DATA GIVEN TO TRAIN\n",
    "# DUE COMPUTATIONAL ISSUES ON MY LAPTOP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
